{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, pandas as pd, numpy as np, string, json, math\n",
    "from pandas.io.json import json_normalize\n",
    "from random import randrange, shuffle\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data/\"\n",
    "\n",
    "REPORTS_FOLDER = \"../data/outputs/synthetic_reports/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_catalog_df = pd.read_csv(\"{}metrics_catalog_synthetic_v1_19feb20.csv\".format(DATA_FOLDER + \"outputs/\"))\n",
    "\n",
    "col_met_mapping = pd.read_csv(\"{}col_met_mapping_v1_19feb20.csv\".format(DATA_FOLDER + \"outputs/\"))\n",
    "\n",
    "owners_df = pd.read_csv(\"{}rep_owner_mapping_v1_19feb20.csv\".format(DATA_FOLDER + \"outputs/\"))\n",
    "\n",
    "users_df = pd.read_csv(\"{}rep_users_mapping_v1_19feb20.csv\".format(DATA_FOLDER + \"outputs/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticSearchIndexer():\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    1. Search and fetch all/new reports from sharepoint\n",
    "    2. Fetch/create updated metric-report mapping\n",
    "    3. Prepare indexing data\n",
    "    4. Connect/Fetch connecter object to ElasticSearch\n",
    "    5. Run index\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    REPORTS_FOLDER = \"../data/outputs/synthetic_reports/\"\n",
    "    \n",
    "    OUTPUT_FOLDER = \"../data/outputs/\"    \n",
    "    \n",
    "    COL_MET_MAP_FNAME = \"{}col_met_mapping_v1_19feb20.csv\".format(OUTPUT_FOLDER)\n",
    "    \n",
    "    def __init__(self, \n",
    "                 es_connector_obj,\n",
    "                es_index_name = \"test\",\n",
    "                 es_doctype = \"metric_report_mapping\"\n",
    "                ):\n",
    "        \n",
    "        self.ES_CONNECTOR = es_connector_obj\n",
    "        \n",
    "        self.ES_INDEX_NAME = es_index_name\n",
    "        \n",
    "        self.ES_DOCTYPE = es_doctype\n",
    "        \n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def run_index(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Main function\n",
    "        Runs all individual components\n",
    "        \"\"\"\n",
    "        \n",
    "        self.report_names = self.fetch_report_names()\n",
    "        \n",
    "        self.met_rep_map = self.fetch_metric_report_map()\n",
    "        \n",
    "        self.index_data = self.prepare_indexing_data()\n",
    "        \n",
    "        self.ES_CONNECTOR = self.connect_es()\n",
    "        \n",
    "        self.index()\n",
    "        \n",
    "        print(\"Indexing complete\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def fetch_report_names(self):\n",
    "        \"\"\"\n",
    "        To be updated after connecting to sharepoint\n",
    "        \n",
    "        Just reads filenames from directory for now.        \n",
    "        \"\"\"\n",
    "        print(\"fetching report names.....\")\n",
    "        \n",
    "        report_names = os.listdir(self.REPORTS_FOLDER)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return report_names\n",
    "    \n",
    "    def _get_rep_colnames(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Fetches report and its column names from reports folder.\n",
    "        \n",
    "        To be updated/replaced with relevant functionality from SharePoint API\n",
    "        \"\"\"\n",
    "        \n",
    "        report_names = os.listdir(self.REPORTS_FOLDER)\n",
    "        \n",
    "        colname_df = pd.DataFrame(columns=[\"repname\", \"colname\"])\n",
    "    \n",
    "        for rep in report_names:\n",
    "            \n",
    "            rep_path = os.path.join(self.REPORTS_FOLDER, rep)\n",
    "            \n",
    "            colnames = pd.read_excel(rep_path, nrows=0).columns.tolist()\n",
    "            \n",
    "            temp_colname_df = pd.DataFrame({\"colname\":colnames})\n",
    "            \n",
    "            temp_colname_df[\"repname\"] = rep\n",
    "            \n",
    "            colname_df = pd.concat([temp_colname_df, colname_df])\n",
    "        \n",
    "        return colname_df\n",
    "    \n",
    "    def fetch_metric_report_map(self):\n",
    "        \"\"\"\n",
    "        To be updated after connecting to sharepoint\n",
    "        \n",
    "        For now creates the metric report map data from col-metric mapping file\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"fetching/creating metric-report mapping file.....\")\n",
    "        \n",
    "        col_met_map = pd.read_csv(self.COL_MET_MAP_FNAME)\n",
    "        \n",
    "        rep_colnames_df = self._get_rep_colnames()\n",
    "        \n",
    "        met_rep_map = rep_colnames_df.merge(col_met_map, left_on=\"colname\", right_on=\"column_names\", how=\"left\")\n",
    "        \n",
    "        met_rep_map.drop_duplicates(subset=[\"repname\", \"metric_names\", \"colname\"], inplace=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return met_rep_map[[\"metric_names\", \"repname\", \"colname\"]]\n",
    "    \n",
    "    def prepare_indexing_data(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Preprocessing data to be indexed\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"pre-processing data to be indexed....\")\n",
    "        \n",
    "        met_rep_map = self.met_rep_map.copy()\n",
    "        \n",
    "        # There must not be any missing values while indexing        \n",
    "        met_rep_map.fillna(\"<missing>\", inplace=True)\n",
    "        \n",
    "        return met_rep_map\n",
    "    \n",
    "    def connect_es(self):\n",
    "        \n",
    "        print(\"establishing connection to ES.....\")\n",
    "        \n",
    "        return self.ES_CONNECTOR\n",
    "    \n",
    "    \n",
    "    def _mapping_df_generator(self, df):\n",
    "        \n",
    "        \"\"\"\n",
    "        Yields a generator that iterates through metric-report name mapping file\n",
    "        \"\"\"\n",
    "        \n",
    "        df_iter = df.iterrows()\n",
    "        \n",
    "        for index, document in df_iter:\n",
    "            \n",
    "            \n",
    "            yield {\n",
    "                    \"_index\": self.ES_INDEX_NAME,\n",
    "                \n",
    "                    \"_doc\": self.ES_DOCTYPE,\n",
    "                \n",
    "                    \"_id\" : f\"{index}\",\n",
    "                \n",
    "                    \"_source\": document.to_dict(),\n",
    "                \n",
    "                }\n",
    "            \n",
    "        raise StopIteration\n",
    "    \n",
    "    def create_index_with_mappings_settings(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Creates an empty index with settings and mappings\n",
    "        \n",
    "        Custom underscore tokenizers has been used\n",
    "        \"\"\"\n",
    "        \n",
    "        index_map_setts = \\\n",
    "                    { \n",
    "                       'mappings':{ \n",
    "                          'properties':{ \n",
    "                             'colname':{ \n",
    "                                'type':'text',\n",
    "                                \"analyzer\":\"metric_names_analyzer\",# this is the analyzer with underscore tokenizer\n",
    "                                \"search_analyzer\":\"standard\"#while search time, just use normal tokenizer\n",
    "                             },\n",
    "                             'metric_names':{ \n",
    "                                'type':'text',\n",
    "                                \"analyzer\":\"metric_names_analyzer\",\n",
    "                                \"search_analyzer\":\"standard\"\n",
    "                             },\n",
    "                             'repname':{ \n",
    "                                'type':'text',\n",
    "                                \"analyzer\":\"metric_names_analyzer\",\n",
    "                                \"search_analyzer\":\"standard\"\n",
    "                             },\n",
    "\n",
    "                          }\n",
    "                       },\n",
    "                       \"settings\":{ \n",
    "                          \"analysis\":{ \n",
    "                             \"analyzer\":{ \n",
    "                                \"metric_names_analyzer\":{ #Analyzer to hold underscore tokenizer\n",
    "                                   \"tokenizer\":\"underscore_tokenizer\"\n",
    "                                }\n",
    "                             },\n",
    "                             \"tokenizer\":{ \n",
    "                                \"underscore_tokenizer\":{ #Underscore tokenizer is defined here\n",
    "                                   \"type\":\"pattern\",\n",
    "                                   \"pattern\":\"_\"\n",
    "                                }\n",
    "                             }\n",
    "                          }\n",
    "                       }\n",
    "                    }\n",
    "\n",
    "\n",
    "        if not self.ES_CONNECTOR.indices.exists(index=self.ES_INDEX_NAME):\n",
    "\n",
    "            #Create index if it doesnt exist\n",
    "            #Should you delete if an index already exists?? Skipping for now\n",
    "            \n",
    "            print(\"creating empty index with settings and mappings.....\")\n",
    "            \n",
    "            self.ES_CONNECTOR.indices.create(index=self.ES_INDEX_NAME, body=index_map_setts)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def index(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Indexes data into Elastic Search\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        from elasticsearch import helpers\n",
    "        \n",
    "        mapping_generator = self._mapping_df_generator(self.index_data)\n",
    "        \n",
    "        self.create_index_with_mappings_settings()# Empty index is created now\n",
    "        \n",
    "        helpers.bulk(self.ES_CONNECTOR, mapping_generator)\n",
    "        \n",
    "        print(\"indexing all data now.....\")\n",
    "        \n",
    "        self.ES_CONNECTOR.indices.refresh(self.ES_INDEX_NAME)\n",
    "        \n",
    "        print(self.ES_CONNECTOR.cat.count(self.ES_INDEX_NAME, params={\"format\": \"json\"}))\n",
    "        \n",
    "        return\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "esi = ElasticSearchIndexer(Elasticsearch(), es_index_name=\"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching report names.....\n",
      "fetching/creating metric-report mapping file.....\n",
      "pre-processing data to be indexed....\n",
      "establishing connection to ES.....\n",
      "indexing all data now.....\n",
      "[{'epoch': '1582210261', 'timestamp': '14:51:01', 'count': '2333'}]\n",
      "Indexing complete\n"
     ]
    }
   ],
   "source": [
    "esi.run_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
